{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12MDa7R1KEDRHaR_mBnpADS2a3d6aYzK3",
      "authorship_tag": "ABX9TyOuvGeu6tHhFnogEZra6nIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teeokh/Bird-Call-Classifier/blob/main/bird_call_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIYcwv2kurq-"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install tensorflow-io\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "4fFPe4D22VBv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the files\n",
        "\n",
        "CAPUCHIN_FILE = os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\" ,\"Parsed_Capuchinbird_Clips\", \"XC3776-3.wav\")\n",
        "NON_CAPUCHIN_FILE = os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\", \"Parsed_Not_Capuchinbird_Clips\", \"afternoon-birds-song-in-forest-0.wav\")\n"
      ],
      "metadata": {
        "id": "ZCW0Vuc23--z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build function to load the data\n",
        "\n",
        "# Loads and preprocesses the audio to resample into 16k SR, and into mono (1 channel)\n",
        "def load_wav_16k_mono(filename):\n",
        "\n",
        "  # Loads contents of audio file. This returns a string (file_contents)\n",
        "  file_contents = tf.io.read_file(filename)\n",
        "\n",
        "  # Decodes the audio file string, returning the audio array and the sample rate (decode_wav returns this as a tensor into 2 elements)\n",
        "  wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "\n",
        "  # Gets rid of trailing axis? And converts sample rate to an integer (so we can resample)\n",
        "  wav = tf.squeeze(wav, axis=-1)\n",
        "  sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "\n",
        "  # Resamples audio array to 16k SR\n",
        "  wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "\n",
        "  return wav"
      ],
      "metadata": {
        "id": "56hBY6aw4jdx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the waves\n",
        "\n",
        "wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
        "nwave = load_wav_16k_mono(NON_CAPUCHIN_FILE)\n",
        "\n",
        "plt.plot(wave)\n",
        "plt.plot(nwave)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zz48IXaWvoIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths for positive and negative data\n",
        "\n",
        "POS = os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\" ,\"Parsed_Capuchinbird_Clips\")\n",
        "NEG = os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\", \"Parsed_Not_Capuchinbird_Clips\")"
      ],
      "metadata": {
        "id": "ZJeiWY0Ejm-i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tensorflow datasets for each set of files\n",
        "\n",
        "pos = tf.data.Dataset.list_files(POS+'/*.wav')\n",
        "neg = tf.data.Dataset.list_files(NEG+'/*.wav')"
      ],
      "metadata": {
        "id": "-gKMjdaNkFl3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
        "\n",
        "data = positives.concatenate(negatives)"
      ],
      "metadata": {
        "id": "_WTzGczYkR9j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loops through each file and collects the length in samples\n",
        "\n",
        "lengths = []\n",
        "for file in os.listdir(os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\" ,\"Parsed_Capuchinbird_Clips\")):\n",
        "\ttensor_wave = load_wav_16k_mono(os.path.join(\"/content/drive/MyDrive/Datasets/Bird_Call_Data\" ,\"Parsed_Capuchinbird_Clips\", file))\n",
        "\tlengths.append(len(tensor_wave))\n",
        "\n",
        "lengths"
      ],
      "metadata": {
        "id": "Y6NpDp5ip1T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_mean(lengths)"
      ],
      "metadata": {
        "id": "kYS5sYWLa3V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_min(lengths)"
      ],
      "metadata": {
        "id": "b_e2UlEubxVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_max(lengths)"
      ],
      "metadata": {
        "id": "ETSMyRXJb1rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess (file_path, label):\n",
        "\twav = load_wav_16k_mono(file_path)\n",
        "\twav = wav[:48000] # Caps the samples to 48000 length (too long = more time loading)\n",
        "\n",
        "\tzero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "\twav = tf.concat([zero_padding, wav],0)\n",
        "\t# If file_path is shorter than 48000, then it fills the rest with 0's\n",
        "\n",
        "\tspectrogram = tf.signal.stft(wav, frame_length = 320, frame_step = 32)\n",
        "\tspectrogram = tf.abs(spectrogram)\n",
        "\tspectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "\n",
        "\treturn spectrogram, label"
      ],
      "metadata": {
        "id": "NYrtalhWsQQk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath, label = negatives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n",
        "spectrogram, label = preprocess(filepath, label)\n",
        "spectrogram"
      ],
      "metadata": {
        "id": "PqOoM85fxARf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(tf.transpose(spectrogram)[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XpB3MAlmDs42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.map(preprocess) #Runs each file in the data through preprocess to\n",
        "# create spectrograms\n",
        "data = data.cache()\n",
        "data = data.shuffle(buffer_size=1000) # Shuffles data\n",
        "data = data.batch(16) # Train on 16 examples at a time\n",
        "data = data.prefetch(8) # Eliminates CPU bottlenecking"
      ],
      "metadata": {
        "id": "grb7cCz1GOj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_number = tf.math.round(len(data)*0.7) # Training split = 70% of data\n",
        "training_number = tf.cast(training_number, tf.int64) # Converts the number to int64 - so it can be used in take and skip\n",
        "\n",
        "train = data.take(training_number)\n",
        "test = data.skip(training_number).take((len(data) - training_number))"
      ],
      "metadata": {
        "id": "OtijmSgMJNeU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples, labels = train.as_numpy_iterator().next()\n",
        "examples.shape"
      ],
      "metadata": {
        "id": "wZAItDk0LNI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building deep learning model:"
      ],
      "metadata": {
        "id": "eJ8LqGk8MI77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
      ],
      "metadata": {
        "id": "BG5W__7PMNCW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), activation=\"relu\", input_shape=(1491, 257, 1)))\n",
        "model.add(Conv2D(16, (3,3), activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "wleOJCttMVJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\"Adam\", loss=\"BinaryCrossentropy\", metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
      ],
      "metadata": {
        "id": "oquMcqMDa4ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "pcQ6-HDudl3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hist = model.fit(train, epochs = 4, validation_data=test)"
      ],
      "metadata": {
        "id": "HD2ePzR6d7ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "dBUOXbsXhbnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "id": "4mqxtSZiiHzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]"
      ],
      "metadata": {
        "id": "BDltSK0kiVyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.reduce_sum(yhat)\n"
      ],
      "metadata": {
        "id": "GE1h1p_SjjOz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}